{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda71d610001774462b94f8ff5fddfbaa01",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SDK version: 1.17.0\n"
     ]
    }
   ],
   "source": [
    "# verify installation and check Azure ML SDK version\n",
    "import azureml.core\n",
    "\n",
    "print('SDK version:', azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Workspace name: HPO-Workspace-Nanthini\n",
      "Azure region: eastus\n",
      "Subscription id: 73612009-b37b-413f-a3f7-ec02f12498cf\n",
      "Resource group: RAPIDS-HPO-Nanthini\n",
      "Default datastore's name: workspaceblobstore\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "print(\"Default datastore's name: {}\".format(datastore.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found compute target. Will use gpu-cluster \n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2020-11-06T21:08:52.544000+00:00', 'errors': None, 'creationTime': '2020-11-06T18:44:21.840391+00:00', 'modifiedTime': '2020-11-06T18:44:38.935614+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 5, 'nodeIdleTimeBeforeScaleDown': 'PT300S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6S_V3'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "gpu_cluster_name = 'gpu-cluster'\n",
    "\n",
    "if gpu_cluster_name in ws.compute_targets:\n",
    "    gpu_cluster = ws.compute_targets[gpu_cluster_name]\n",
    "    if gpu_cluster and type(gpu_cluster) is AmlCompute:\n",
    "        print('Found compute target. Will use {0} '.format(gpu_cluster_name))\n",
    "else:\n",
    "    print('creating new cluster')\n",
    "    # m_size parameter below could be modified to one of the RAPIDS-supported VM types\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = 'Standard_NC6s_v3', max_nodes = 5, idle_seconds_before_scaledown = 300)\n",
    "    # Use VM types with more than one GPU for multi-GPU option, e.g. Standard_NC12s_v3\n",
    "    \n",
    "    # create the cluster\n",
    "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    gpu_cluster.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "# use get_status() to get a detailed status for the current cluster \n",
    "print(gpu_cluster.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Workspace name: HPO-Workspace-Nanthini\n",
      "Azure region: eastus\n",
      "Subscription id: 73612009-b37b-413f-a3f7-ec02f12498cf\n",
      "Resource group: RAPIDS-HPO-Nanthini\n",
      "Default datastore's name: workspaceblobstore\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "print(\"Default datastore's name: {}\".format(datastore.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'optuna_rapids'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "# create the environment\n",
    "rapids_env = Environment('rapids_env')\n",
    "\n",
    "# create the environment inside a Docker container\n",
    "rapids_env.docker.enabled = True\n",
    "\n",
    "# specify docker steps as a string. Alternatively, load the string from a file\n",
    "dockerfile = \"\"\"\n",
    "FROM rapidsai/rapidsai:0.16-cuda10.2-runtime-ubuntu18.04-py3.7\n",
    "RUN apt-get update && \\\n",
    "apt-get install -y fuse && \\\n",
    "apt-get install libssl1.0.0 libssl-dev && \\\n",
    "source activate rapids && \\\n",
    "pip install azureml-sdk==1.13.0 && \\\n",
    "pip install azureml-widgets && \\\n",
    "pip install optuna && \\\n",
    "pip install dask_optuna && \\\n",
    "pip install fusepy\n",
    "\"\"\"\n",
    "\n",
    "# set base image to None since the image is defined by dockerfile\n",
    "rapids_env.docker.enabled = True\n",
    "rapids_env.docker.base_image = None\n",
    "rapids_env.docker.base_dockerfile = dockerfile\n",
    "\n",
    "# use rapids environment in the container\n",
    "rapids_env.python.user_managed_dependencies = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "bnp_ds = Dataset.File.from_files(\"https://kagglebnpdataset.blob.core.windows.net/data/bnp_train.csv\")\n",
    "bnp_ds.download(target_path='data/')\n",
    "path_on_datastore = 'bnp_upload'\n",
    "datastore.upload(src_dir='data/', target_path=path_on_datastore, overwrite=False, show_progress=True)\n",
    "\n",
    "ds_data = datastore.path(path_on_datastore)\n",
    "dataset = Dataset.File.from_files(ds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = ['--data_dir', bnp_ds.as_named_input('bnp_input').as_mount(),\n",
    "]\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "project_folder =\"./\"\n",
    "src = ScriptRunConfig(source_directory=project_folder,\n",
    "                      script='train_optuna.py',\n",
    "                      arguments=script_params,\n",
    "                      compute_target=\"gpu-cluster\",\n",
    "                      environment=rapids_env)\n",
    "\n",
    "# Set compute target\n",
    "# Skip this if you are running on your local computer\n",
    "# src.run_config.target = gpu_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(config=src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RunId: optuna_rapids_1604700066_1c2d31bc\n",
      "Web View: https://ml.azure.com/experiments/optuna_rapids/runs/optuna_rapids_1604700066_1c2d31bc?wsid=/subscriptions/73612009-b37b-413f-a3f7-ec02f12498cf/resourcegroups/RAPIDS-HPO-Nanthini/workspaces/HPO-Workspace-Nanthini\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_20d88174fa3e7c6c499639580a6932da81cf902230f1e12c5f607c2a625f3b41_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-11-06T22:05:16Z Starting output-watcher...\n",
      "2020-11-06T22:05:16Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2020-11-06T22:05:18Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2020-11-06T22:05:18Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_d446b97076f6c20a6046fbda4aba0d62\n",
      "171857c49d0f: Pulling fs layer\n",
      "419640447d26: Pulling fs layer\n",
      "61e52f862619: Pulling fs layer\n",
      "c118dad7e37a: Pulling fs layer\n",
      "29c091e4be16: Pulling fs layer\n",
      "d85c81a4428d: Pulling fs layer\n",
      "e6ba6b94dd40: Pulling fs layer\n",
      "6f6dd4b091bb: Pulling fs layer\n",
      "29c091e4be16: Waiting\n",
      "d85c81a4428d: Waiting\n",
      "e6ba6b94dd40: Waiting\n",
      "99b4b454233b: Pulling fs layer\n",
      "4772f8780444: Pulling fs layer\n",
      "fa247e248e0e: Pulling fs layer\n",
      "a08428fae96a: Pulling fs layer\n",
      "82a1e2eefea2: Pulling fs layer\n",
      "c118dad7e37a: Waiting\n",
      "6f6dd4b091bb: Waiting\n",
      "99b4b454233b: Waiting\n",
      "4772f8780444: Waiting\n",
      "a08428fae96a: Waiting\n",
      "fa247e248e0e: Waiting\n",
      "82a1e2eefea2: Waiting\n",
      "61e52f862619: Verifying Checksum\n",
      "61e52f862619: Download complete\n",
      "419640447d26: Verifying Checksum\n",
      "419640447d26: Download complete\n",
      "c118dad7e37a: Verifying Checksum\n",
      "c118dad7e37a: Download complete\n",
      "171857c49d0f: Verifying Checksum\n",
      "171857c49d0f: Download complete\n",
      "29c091e4be16: Verifying Checksum\n",
      "29c091e4be16: Download complete\n",
      "d85c81a4428d: Verifying Checksum\n",
      "d85c81a4428d: Download complete\n",
      "171857c49d0f: Pull complete\n",
      "419640447d26: Pull complete\n",
      "61e52f862619: Pull complete\n",
      "c118dad7e37a: Pull complete\n",
      "29c091e4be16: Pull complete\n",
      "d85c81a4428d: Pull complete\n",
      "6f6dd4b091bb: Verifying Checksum\n",
      "6f6dd4b091bb: Download complete\n",
      "e6ba6b94dd40: Verifying Checksum\n",
      "e6ba6b94dd40: Download complete\n",
      "fa247e248e0e: Verifying Checksum\n",
      "fa247e248e0e: Download complete\n",
      "a08428fae96a: Verifying Checksum\n",
      "a08428fae96a: Download complete\n",
      "82a1e2eefea2: Verifying Checksum\n",
      "82a1e2eefea2: Download complete\n",
      "99b4b454233b: Verifying Checksum\n",
      "99b4b454233b: Download complete\n",
      "4772f8780444: Verifying Checksum\n",
      "4772f8780444: Download complete\n",
      "e6ba6b94dd40: Pull complete\n",
      "6f6dd4b091bb: Pull complete\n",
      "99b4b454233b: Pull complete\n",
      "4772f8780444: Pull complete\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_20d88174fa3e7c6c499639580a6932da81cf902230f1e12c5f607c2a625f3b41_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2020-11-06T22:09:21.940065] Entering job release\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azureml-telemetry 1.17.0 (/opt/conda/envs/rapids/lib/python3.7/site-packages), Requirement.parse('azureml-telemetry~=1.13.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azureml-telemetry 1.17.0 (/opt/conda/envs/rapids/lib/python3.7/site-packages), Requirement.parse('azureml-telemetry~=1.13.0'), {'azureml-automl-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.17.0 (/opt/conda/envs/rapids/lib/python3.7/site-packages), Requirement.parse('azureml-core~=1.13.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.17.0 (/opt/conda/envs/rapids/lib/python3.7/site-packages), Requirement.parse('azureml-core~=1.13.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.17.0 (/opt/conda/envs/rapids/lib/python3.7/site-packages), Requirement.parse('azureml-core~=1.13.0')).\n",
      "[2020-11-06T22:09:22.760748] Starting job release\n",
      "[2020-11-06T22:09:22.761260] Logging experiment finalizing status in history service.\n",
      "[2020-11-06T22:09:22.761389] job release stage : upload_datastore starting...Starting the daemon thread to refresh tokens in background for process with pid = 694\n",
      "\n",
      "[2020-11-06T22:09:22.761751] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2020-11-06T22:09:22.761964] job release stage : execute_job_release starting...\n",
      "[2020-11-06T22:09:22.763730] job release stage : copy_batchai_cached_logs starting...\n",
      "[2020-11-06T22:09:22.763935] job release stage : copy_batchai_cached_logs completed...\n",
      "[2020-11-06T22:09:22.764453] Entering context manager injector.\n",
      "[2020-11-06T22:09:22.771551] job release stage : upload_datastore completed...\n",
      "[2020-11-06T22:09:22.981245] job release stage : send_run_telemetry starting...\n",
      "[2020-11-06T22:09:23.093139] job release stage : execute_job_release completed...\n",
      "[2020-11-06T22:09:24.200122] job release stage : send_run_telemetry completed...\n",
      "[2020-11-06T22:09:24.200320] Job release is complete\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: optuna_rapids_1604700066_1c2d31bc\n",
      "Web View: https://ml.azure.com/experiments/optuna_rapids/runs/optuna_rapids_1604700066_1c2d31bc?wsid=/subscriptions/73612009-b37b-413f-a3f7-ec02f12498cf/resourcegroups/RAPIDS-HPO-Nanthini/workspaces/HPO-Workspace-Nanthini\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\",\n        \"details\": []\n    },\n    \"correlation\": {\n        \"operation\": null,\n        \"request\": \"b15c057097c1251d\"\n    },\n    \"environment\": \"eastus\",\n    \"location\": \"eastus\",\n    \"time\": \"2020-11-06T22:09:35.094116Z\",\n    \"componentName\": \"execution-worker\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n        \\\"request\\\": \\\"b15c057097c1251d\\\"\\n    },\\n    \\\"environment\\\": \\\"eastus\\\",\\n    \\\"location\\\": \\\"eastus\\\",\\n    \\\"time\\\": \\\"2020-11-06T22:09:35.094116Z\\\",\\n    \\\"componentName\\\": \\\"execution-worker\\\"\\n}\"\n    }\n}",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-c525ff7b8c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    721\u001b[0m                     \u001b[0mfile_handle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                     \u001b[0mwait_post_processing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_post_processing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m                     raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    724\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    962\u001b[0m                 \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\",\n        \"details\": []\n    },\n    \"correlation\": {\n        \"operation\": null,\n        \"request\": \"b15c057097c1251d\"\n    },\n    \"environment\": \"eastus\",\n    \"location\": \"eastus\",\n    \"time\": \"2020-11-06T22:09:35.094116Z\",\n    \"componentName\": \"execution-worker\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n        \\\"request\\\": \\\"b15c057097c1251d\\\"\\n    },\\n    \\\"environment\\\": \\\"eastus\\\",\\n    \\\"location\\\": \\\"eastus\\\",\\n    \\\"time\\\": \\\"2020-11-06T22:09:35.094116Z\\\",\\n    \\\"componentName\\\": \\\"execution-worker\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}